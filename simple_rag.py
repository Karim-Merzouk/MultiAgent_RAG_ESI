# -*- coding: utf-8 -*-
"""simple rag.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1psUf7vQ0Qk-eBeaSlS8SZPrU3qBHTAcK
"""

from langchain_community.document_loaders import TextLoader, WebBaseLoader, PyPDFLoader,DirectoryLoader,UnstructuredMarkdownLoader
import bs4
import os
from dotenv import load_dotenv
# from langchain_community.document_loaders import PyPDFDirectoryLoader
# loader = PyPDFDirectoryLoader('file/')
# txt = loader.load()
loader = DirectoryLoader(
    path="OUTPUT_TXT_sys",  # Replace with your folder path
    loader_cls=UnstructuredMarkdownLoader,       # Use TextLoader for .txt files
    use_multithreading=True      # Optional: speed up loading
)

txt = loader.load()

# !pip install markdown

from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings
from langchain_community.vectorstores import FAISS
from pydantic.v1 import BaseModel, Field
import os

# Add this before your FAISS imports
class VectorStoreConfig(BaseModel):
    class Config:
        arbitrary_types_allowed = True


# Text splitting
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,  # Characters (adjust for token limits)
    chunk_overlap=200,
    separators=[
        # ----- Markdown -----
        # Headers (regex: newline + #)
        r"\n# ", r"\n## ", r"\n### ", r"\n#### ",
        r"\n```\n",                                 # Code block boundaries
        # Horizontal rules (*** or ---)
        r"\n\*\*\*\n", r"\n---\n",

        # ----- LaTeX/Math -----
        r"\n\\begin{equation}",                     # LaTeX equations
        r"\n\\begin{align}",                        # Math align environments
        r"\n\\section{", r"\n\\subsection{",        # LaTeX sections
        r"\n\$\$", r"\n\\\[",                       # Display math boundaries

        # ----- C Code -----
        r"\n}\n",                                   # End of code blocks/functions
        # Comment separators (e.g., // ----)
        r"\n// -{4,}\n",
        r"\n#ifdef ", r"\n#endif",                  # Preprocessor directives
        r"\n}\n\n",                                 # Double newline after braces

        # ----- Assembly -----
        # Section directives (e.g., .section .text)
        r"\n\.section\s",
        r"\n\.global\s",                            # Global labels
        r"\n[a-zA-Z_]+:\n",                         # Labels (e.g., "main:\n")
        # Assembly comment separators (e.g., ; ----)
        r"\n; -{4,}\n",

        # ----- Generic Fallbacks -----
        r"\n\n", r"\n", r" ", r""                  # Standard text fallbacks
    ],
    is_separator_regex=True,   # Enable regex mode for all separators
    keep_separator=True,       # Retain separators in chunks (e.g., headers)
    # Clean trailing/leading whitespace (except in code)
    strip_whitespace=True,
)
fdocs = text_splitter.split_documents(txt)

# Embedding with CPU optimization
embeddings = SentenceTransformerEmbeddings(
    model_name="all-MiniLM-L12-v2",
    model_kwargs={"device": "cpu"},
    encode_kwargs={
        "batch_size": 64,  # Process 64 chunks at once
        "normalize_embeddings": True  # Better for similarity
    }
)

# Create FAISS index (without persist_directory which is not supported)
db = FAISS.from_documents(
    documents=fdocs,
    embedding=embeddings,
    normalize_L2=True  # Reduces memory usage
)

# Save the FAISS index to disk (FAISS uses a different persistence method)
save_directory = "./faiss_index"
os.makedirs(save_directory, exist_ok=True)
db.save_local(save_directory)

# To load it back later, you would use:
# loaded_db = FAISS.load_local(save_directory, embeddings)

from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_ollama import ChatOllama

from langchain_core.prompts import  ChatPromptTemplate

llm = ChatOllama(
    model="llama3",  # Version de base (gardée selon votre demande)
    temperature=0,
    num_ctx=2048,        # Réduction du contexte mémoire
    num_thread=8,        # 1 thread par cœur physique (8 cores/16 threads)
    num_gpu=0,           # Désactivation explicite du GPU intégré
    use_mlock=True,  )    # Prévention du swapping mémoire


prompt = ChatPromptTemplate.from_template('''[Contexte] {context}
[Question] {input}

**Instructions Stricte** :
1. **Langue** :
   - Français avec des mots clés en Anglais
   - Registre académique formel

2. **Contenu** :
   - Priorité absolue aux concepts théoriques du cours
   - Exercices UNIQUEMENT si :
     a) La question le demande explicitement
     b) Nécessaire pour illustrer une application critique
   - Max 1 exemple/application par concept majeur
   - si la question était sur assambly, donc c'est assambly 8086, et tu doit suivre la même syntax avec les document de context, il n ya pas de registre 32bit , just 16 bit

3. **Structure Obligatoire** :
```markdown
## Introduction
- Contextualisation du sujet
- Énoncé de l'objectif principal

## Développement Structuré
### Concepts Clés
- Définitions formelles (théorèmes, formules)
- Propriétés essentielles (listes à puces)

### Explications Détaillées
- Logique mathématique (si > alors...)
- Diagrammes conceptuels (en pseudo-code Markdown)

### Applications Ciblées
[Conditionnel : UNIQUEMENT si pertinent]
- 1 exemple minimal viable (code LaTeX/Markdown ou blocs C/ASM)
- Cas d'usage typique

## Conclusion Synthétique
- Résumé en 3 points maximum
- Liens avec les chapitres suivants (si pertinent)
''')
document_chain= create_stuff_documents_chain(llm,prompt)

from pprint import pprint
from IPython.display import Markdown, display

from langchain.chains import create_retrieval_chain

retriver = db.as_retriever()



retriver_chain= create_retrieval_chain(retriver,document_chain)


res = retriver_chain.invoke({'input':"donne un program assambleur  pour entrer un nom et le convertir vers majiscule et l'afficher"})


pprint(res['answer'])

from pprint import pprint
display(Markdown(res['answer']))

# pprint(res['answer'])


from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import TextLoader, WebBaseLoader, PyPDFLoader, DirectoryLoader, UnstructuredMarkdownLoader
import bs4
import os

# Document loading
loader = DirectoryLoader(
    path="OUTPUT_TXT_sys",  # Replace with your folder path
    loader_cls=UnstructuredMarkdownLoader,
    use_multithreading=True
)

txt = loader.load()
from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings
from langchain_community.vectorstores import FAISS
from pydantic.v1 import BaseModel, Field
import os

# Add this before your FAISS imports
class VectorStoreConfig(BaseModel):
    class Config:
        arbitrary_types_allowed = True


# Text splitting
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200,
    separators=[
        # ----- Markdown -----
        r"\n# ", r"\n## ", r"\n### ", r"\n#### ",
        r"\n```\n",
        r"\n\*\*\*\n", r"\n---\n",

        # ----- LaTeX/Math -----
        r"\n\\begin{equation}",
        r"\n\\begin{align}",
        r"\n\\section{", r"\n\\subsection{",
        r"\n\$\$", r"\n\\\[",

        # ----- C Code -----
        r"\n}\n",
        r"\n// -{4,}\n",
        r"\n#ifdef ", r"\n#endif",
        r"\n}\n\n",

        # ----- Assembly -----
        r"\n\.section\s",
        r"\n\.global\s",
        r"\n[a-zA-Z_]+:\n",
        r"\n; -{4,}\n",

        # ----- Generic Fallbacks -----
        r"\n\n", r"\n", r" ", r""
    ],
    is_separator_regex=True,
    keep_separator=True,
    strip_whitespace=True,
)
fdocs = text_splitter.split_documents(txt)

# Embedding with CPU optimization
embeddings = SentenceTransformerEmbeddings(
    model_name="all-MiniLM-L12-v2",
    model_kwargs={"device": "cpu"},
    encode_kwargs={
        "batch_size": 64,
        "normalize_embeddings": True
    }
)

# Create FAISS index
db = FAISS.from_documents(
    documents=fdocs,
    embedding=embeddings,
    normalize_L2=True
)

# Save the FAISS index to disk
save_directory = "./faiss_index"
os.makedirs(save_directory, exist_ok=True)
db.save_local(save_directory)

# To load it back later:
# loaded_db = FAISS.load_local(save_directory, embeddings)

# Now let's modify to use GROQ API instead of Ollama
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_groq import ChatGroq  # Import the GROQ chat model
from langchain_core.prompts import ChatPromptTemplate
import os

# Set your GROQ API key - make sure to keep this secure!
# Import the API key from a separate .env file for better security
load_dotenv()  # Load environment variables from .env file

# The API key should be stored in a .env file as GROQ_API_KEY=your_api_key
# This avoids hardcoding sensitive credentials in your code

# Initialize the GROQ LLM - replaced Ollama with GROQ
llm = ChatGroq(
    model="llama3-70b-8192",  # You can choose "mixtral-8x7b-32768" or other models
    temperature=0,
    max_tokens=4096,  # Control response length
)

# The prompt template remains the same
prompt = ChatPromptTemplate.from_template('''[Contexte] {context}
[Question] {input}

**Instructions Stricte** :
1. **Langue** :
   - Français avec des mots clés en Anglais
   - Registre académique formel

2. **Contenu** :
   - Priorité absolue aux concepts théoriques du cours
   - Exercices UNIQUEMENT si :
     a) La question le demande explicitement
     b) Nécessaire pour illustrer une application critique
   - Max 1 exemple/application par concept majeur
   - si la question était sur assambly, donc c'est assambly 8086, et tu doit suivre la même syntax avec les document de context, il n ya pas de registre 32bit , just 16 bit

3. **Structure Obligatoire** :
```markdown
## Introduction
- Contextualisation du sujet
- Énoncé de l'objectif principal

## Développement Structuré
### Concepts Clés
- Définitions formelles (théorèmes, formules)
- Propriétés essentielles (listes à puces)

### Explications Détaillées
- Logique mathématique (si > alors...)
- Diagrammes conceptuels (en pseudo-code Markdown)

### Applications Ciblées
[Conditionnel : UNIQUEMENT si pertinent]
- 1 exemple minimal viable (code LaTeX/Markdown ou blocs C/ASM)
- Cas d'usage typique

## Conclusion Synthétique
- Résumé en 3 points maximum
- Liens avec les chapitres suivants (si pertinent)
''')

# Create document chain
document_chain = create_stuff_documents_chain(llm, prompt)

# Create retrieval chain
retriever = db.as_retriever(
    search_kwargs={"k": 4}  # Retrieve top 4 most relevant documents
)

from langchain.chains import create_retrieval_chain

retriever_chain = create_retrieval_chain(retriever, document_chain)

# Example usage
def query_system(question):
    result = retriever_chain.invoke({'input': question})
    return result['answer']

# Example query
if __name__ == "__main__":
    from pprint import pprint


    # Example query
    query = "donne un program assambleur pour entrer un nom et le convertir vers majiscule et l'afficher"
    response = query_system(query)

    print("\n===== RÉPONSE =====\n")
    print(response)